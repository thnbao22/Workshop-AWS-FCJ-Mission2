[
{
	"uri": "/1-introductiontoterraform/",
	"title": "Introduction to Terraform",
	"tags": [],
	"description": "",
	"content": "\nOverview What is Terraform? Terraform is an infrastructure as code tool that lets you build, change, and version infrastructure safely and efficiently.\nThis includes low-level components like compute instances, storage, and networking; and high-level components like DNS entries and SaaS features.\nHow does Terraform work? Terraform creates and manages resources on cloud platforms and other services through their application programming interfaces (APIs). Providers enable Terraform to work with virtually any platform or service with an accessible API.\nThe core Terraform workflow consists of three stages:\nWrite: You define resources, which may be across multiple cloud providers and services. Plan: Terraform creates an execution plan describing the infrastructure it will create, update, or destroy based on the existing infrastructure and your configuration. Apply: On approval, Terraform performs the proposed operations in the correct order, respecting any resource dependencies. Content Terraform Fundamentals Terraform CLI Set up "
},
{
	"uri": "/2-defineinfrastructure/2.1networking/",
	"title": "Networking",
	"tags": [],
	"description": "",
	"content": "\nOverview About Networking, we have some components such as VPC (Virtual Private Server), Subnets, Internet Gateway and Route Table (and also have Security Group).\nWe need to create a VPC before we can create public subnets, route table, security group and internet Gateway.\nVPC Based on the architecture above, we know that we need to create a VPC with CIDR 10.10.0.0/16 in region Singapore, which has 2 Public Subnets with CIDR 10.10.1.0/24 and 10.10.2.0/24. Public Subent 1 resides in ap-southeast-1a and the other resides in ap-southeast-1b.\nInternet Gateway The purpose of the Internet Gateway is to enable the Instance in the public subnet to communicate with the Internet.\nRoute Table The Route Table will have 2 public Subnet associations, which will help the Instances in two public Subnets to communicate with the Internet\nSecurity Group We need to create a Security Group for EC2, with inbound rules that allow ALB and SSH connections from our local machine. Plus, security group for ALB allow trafic from internet.\nNext, we will continue with module Compute\n"
},
{
	"uri": "/3-infrastructureascode/3.1networking/",
	"title": "Networking",
	"tags": [],
	"description": "",
	"content": "Overview We will build infrastructure based on this architecture. A VPC with 2 Public Subnets. An Internet Gateway attached to the VPC. A Route Table helps route the EC2 in Public Subnets to communicate with the internet.\nSet up Files In the Networking folder, create three files and name them respectively as main.tf, variables.tf, and outputs.tf.\nFirst, we will define the Availability Zones we use in the variables.tf file.\nBy default, we just use 2 AZs, which are ap-southeast-1a and ap-southeast-1b. Define input variable for VPC CIDR.\nvariable \u0026#34;availabitity_zones\u0026#34; {\rdescription = \u0026#34;AZs in this region to use\u0026#34;\rdefault = [\u0026#34;ap-southeast-1a\u0026#34;, \u0026#34;ap-southeast-1b\u0026#34;]\r}\rvariable \u0026#34;cidr_block\u0026#34; {\r} In the main.tf file, we just simply create some resources such as VPC, Public Subnets, Route Table, Security Group and Internet Gateway.\nVPC We will use resources aws_vpc to provide a VPC resource. You can read more about this resource at here.\nresource \u0026#34;aws_vpc\u0026#34; \u0026#34;one-tier-vpc\u0026#34; {\rcidr_block = var.cidr_block\renable_dns_hostnames = true\renable_dns_support = true\rtags = {\rName = \u0026#34;vpc-workshop-2\u0026#34;\r}\r} 2 Public Subnets About Subnet, we use the resources aws_subnet to create 2 Public Subnets with CIDR 10.10.1.0/24 and 10.10.2.0/24.\nresource \u0026#34;aws_subnet\u0026#34; \u0026#34;public_subnet_1\u0026#34; {\rvpc_id = aws_vpc.one-tier-vpc.id\ravailability_zone = var.availabitity_zones[0]\rcidr_block = \u0026#34;10.10.1.0/24\u0026#34;\rmap_public_ip_on_launch = true\rtags = {\r\u0026#34;Name\u0026#34; = \u0026#34;Public Subnet 1\u0026#34;\r}\r}\rresource \u0026#34;aws_subnet\u0026#34; \u0026#34;public_subnet_2\u0026#34; {\rvpc_id = aws_vpc.one-tier-vpc.id\ravailability_zone = var.availabitity_zones[1]\rcidr_block = \u0026#34;10.10.2.0/24\u0026#34;\rmap_public_ip_on_launch = true\rtags = {\r\u0026#34;Name\u0026#34; = \u0026#34;Public Subnet 2\u0026#34;\r}\r} Internet Gateway Use resources aws_internet_gateway to attach the IGW to the VPC.\nresource \u0026#34;aws_internet_gateway\u0026#34; \u0026#34;one_tier_igw\u0026#34; {\rvpc_id = aws_vpc.one-tier-vpc.id\rtags = {\r\u0026#34;Name\u0026#34; = \u0026#34;Workshop2 IGW\u0026#34;\r}\r} Route Table Public We use resources aws_route_table to create a Public Route Table. We create a routing table entry by using aws_route, which routes the traffic inside the Public Subnet to the internet through the Internet Gateway.\nLast, we need to associate the Public Route Table with 2 Public Subnets by using the resource aws_route_table_association\nresource \u0026#34;aws_route_table\u0026#34; \u0026#34;public_rt\u0026#34; {\rvpc_id = aws_vpc.one-tier-vpc.id\rtags = {\r\u0026#34;Name\u0026#34; = \u0026#34;Public Route Table\u0026#34;\r}\r}\rresource \u0026#34;aws_route\u0026#34; \u0026#34;public_route\u0026#34; {\rroute_table_id = aws_route_table.public_rt.id\rdestination_cidr_block = \u0026#34;0.0.0.0/0\u0026#34;\rgateway_id = aws_internet_gateway.one_tier_igw.id\r}\rresource \u0026#34;aws_route_table_association\u0026#34; \u0026#34;one_tier_rt_public_associate_1\u0026#34; {\rroute_table_id = aws_route_table.public_rt.id\rsubnet_id = aws_subnet.public_subnet_1.id\r}\rresource \u0026#34;aws_route_table_association\u0026#34; \u0026#34;one_tier_rt_public_associate_2\u0026#34; {\rroute_table_id = aws_route_table.public_rt.id\rsubnet_id = aws_subnet.public_subnet_2.id\r} Public Security Group This data source will help us retrieve the local IP address of our machine.\nYou can read more about this at here.\ndata \u0026#34;http\u0026#34; \u0026#34;local_ip\u0026#34; {\rurl = \u0026#34;https://ipv4.icanhazip.com\u0026#34;\r} We will define 2 inbound rules for Security Group.\nThe first rule is to allow SSH from your local machine. By using the data source, you can retrieve the IPv4 address of your local machine.. The second rule is to allow HTTP from the Application Load Balancer using port 80. resource \u0026#34;aws_security_group\u0026#34; \u0026#34;one_tier_public_sg\u0026#34; {\rname = \u0026#34;Public Security Group\u0026#34;\rdescription = \u0026#34;Allow HTTP and SSH inbound traffic\u0026#34;\rvpc_id = aws_vpc.one-tier-vpc.id\ringress {\rfrom_port = 22\rto_port = 22\rprotocol = \u0026#34;tcp\u0026#34;\rcidr_blocks = [ \u0026#34;${chomp(data.http.local_ip.response_body)}/32\u0026#34; ]\r}\ringress {\rfrom_port = 80\rto_port = 80\rprotocol = \u0026#34;tcp\u0026#34;\rsecurity_groups = [aws_security_group.one_tier_alb_sg.id]\r}\regress {\rfrom_port = 0\rto_port = 0\rprotocol = \u0026#34;-1\u0026#34;\rcidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;]\r}\rlifecycle {\rcreate_before_destroy = true\r}\r} ALB Security Group The ALB security group allows users to pass through the Application Load Balancer from the internet before they can reach the Auto Scaling Groups.\nresource \u0026#34;aws_security_group\u0026#34; \u0026#34;one_tier_alb_sg\u0026#34; {\rname = \u0026#34;ALB Security Group\u0026#34;\rvpc_id = aws_vpc.one-tier-vpc.id\ringress {\rfrom_port = 80\rto_port = 80\rprotocol = \u0026#34;tcp\u0026#34;\rcidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;]\r}\regress {\rfrom_port = 0\rto_port = 0\rprotocol = \u0026#34;-1\u0026#34;\rcidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;]\r}\r} Output After defining resources, we need to output some variables for other resources, like Compute, to use. We will do that in the outputs.tf file.\noutput \u0026#34;vpc_id\u0026#34; {\rvalue = aws_vpc.one-tier-vpc.id\r}\routput \u0026#34;public_subnet_1_id\u0026#34; {\rvalue = aws_subnet.public_subnet_1.id\r}\routput \u0026#34;public_subnet_2_id\u0026#34; {\rvalue = aws_subnet.public_subnet_2.id\r}\routput \u0026#34;public_sg_id\u0026#34; {\rvalue = aws_security_group.one_tier_public_sg.id\r}\routput \u0026#34;alb_sg_id\u0026#34; {\rvalue = aws_security_group.one_tier_alb_sg.id\r} You can see that we output some resources such as the ID of the VPC, the 2 Public Subnets, the Public SG and the ALB SG.\nSo, let\u0026rsquo;s move on to the Compute folder.\n"
},
{
	"uri": "/4.deployinfraandconfiguresns/4.1networkingresources/",
	"title": "Networking Resources",
	"tags": [],
	"description": "",
	"content": "Overview Now, we will review our resources. Access the VPC interface and view some resources such as our VPC, Public Subnets, Internet Gateway and Security Group.\nVPC VPC with CIDR 10.10.0.0/16 2 Public Subnets Public Subnet 1 with CIDR 10.10.1.0/24 Public Subnet 2 with CIDR 10.10.2.0/24 Public Route Table Subnet associations Internet Gateway The internet gateway is attached to the VPC. Public Security Group 2 Inbound rules:\nAllow SSH from the local IP address Allow HTTP from the ALB Security Group ALB Security Group 1 Inbound rule:\nAllow HTTP request from the internet Now, let\u0026rsquo;s move on to see our Compute resources.\n"
},
{
	"uri": "/1-introductiontoterraform/1.1-terraformfundamentals/",
	"title": "Terraform Fundamentals",
	"tags": [],
	"description": "",
	"content": "Terraform Basic Folder structure Local values Input variables Output values Providers Resources Data sources State management Terraform documentation Folder structure A typical Folder contains a main.tf, outputs.tf, providers.tf, and variables.tf, where\nmain.tf contains the core resources of the module outputs.tf (Optional) contains the outputs of the module variables.tf (Optional) contains the input variables of the module providers.tf (Optional) contains the provider configuration which gets covered later on Example: main terraform layout\nterraform-test\r├── main.tf\r├── outputs.tf\r├── providers.tf\r└── variables.tf Local Values Local values are named values that are assigned and can be used throughout your code. Local values can be constant or referenced values. Local values are assigned by created a set of locals block as shown below:\nlocals {\r# Assign the value of \u0026#39;dev\u0026#39; to environment\rinstance_name = \u0026#34;dev-instance\u0026#34;\r# Obtain the instance ID of the \u0026#39;app_server\u0026#39; EC2 instance\rinstance_id = aws_instance.app_server.id\r} To use local variables, the format is local.\u0026lt;variable_name\u0026gt;. Here is an example of using a local variable to name the EC2 instance resource.\nresource \u0026#34;aws_instance\u0026#34; \u0026#34;this_server\u0026#34; {\r# ...\rtags = {\r# Using local variable\rName = local.instance_name,\r\u0026#34;Environment\u0026#34; = \u0026#34;dev\u0026#34;\r}\r} Input Variables Input variables are used to provide parameters for you to customize your Terraform module without altering the module\u0026rsquo;s source code and prevent hard-coding values and enabled you to re-use code An example of input variables:\nvariable \u0026#34;app_name\u0026#34; {\rtype = string\rdescription = \u0026#34;Name of the application\u0026#34;\rdefault = \u0026#34;\u0026#34;\r} To use input variables, the format is var.\u0026lt;variable_name\u0026gt;. Here is an example of using the input variable to name the EC2 instance resource:\nresource \u0026#34;aws_instance\u0026#34; \u0026#34;app_server\u0026#34; {\r# ...\rtags = {\r# Using input variable\rName = var.app_name,\r\u0026#34;Environment\u0026#34; = \u0026#34;prod\u0026#34;\r}\r} You can also assign variables using the command line: terraform apply -var=\u0026quot;app_name=wordpress-app\u0026quot;\nOutput Variables Output variables allows you to expose information on the resources so that others Terraform configurations can use it.\nAn example of output variables:\noutput \u0026#34;instance_tags\u0026#34; {\rvalue = aws_instance.this_server.tags\rdescription = \u0026#34;A mapping of EC2 instance tags\u0026#34;\r} Providers Providers provide interactions with cloud providers, Software as a Service (SaaS) providers and other Application Programming Interface (API). Each provider provides a set of resources and data sources that Terraform can manage. Example of an AWS provider:\nterraform {\rrequired_providers {\raws = {\rsource = \u0026#34;hashicorp/aws\u0026#34;\rversion = \u0026#34;5.47.0\u0026#34;\r}\r}\r}\rprovider \u0026#34;aws\u0026#34; {\r# Configuration options\r} Resources Resources are the core element in Terraform. Declaring a resource can define one or more infrastructure resource objects such as compute, networking, etc\nExample of a AWS Simple Storage Service (S3) bucket resource:\nresource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;example\u0026#34; {\rbucket = \u0026#34;workshop2-bucket\u0026#34;\r} Data Sources Data Sources allow lookup of resources defined outside of Terraform and provide the attributes found within that resource\nExample of a data source lookup of an existing AWS Virtual Private Cloud (VPC):\ndata \u0026#34;aws_vpc\u0026#34; \u0026#34;selected\u0026#34; {\rid = \u0026#34;vpc-00f0b02721857a89d\u0026#34;\r} "
},
{
	"uri": "/",
	"title": "Using Terraform to provision infrastructure on AWS Cloud",
	"tags": [],
	"description": "",
	"content": "Using Terraform to provision infrastructure on AWS Cloud Overview In this lab, we will learn how to deploy a highly available infrastructure on AWS using Terraform, a popular infrastructure as code tool.\nArchitecture In this architecture, you can see we have a VPC with CIDR 10.10.0.0/16, which has 2 public subnets with CIDR 10.10.1.0/24 and 10.10.2.0/24. Additionally, the VPC also has an Internet Gateway attached to it.\nBefore we dive into the deployment of our infrastructure, let\u0026rsquo;s take a moment to understand the concept of an Auto Scaling Group, Application Load Balancer and Amazon SNS to find out its role in ensuring the availability and scalability of our applications.\nWe only need to manually create Amazon Simple Notification Service (Amazon SNS) using either AWS Management Console or AWS CLI after deploying the architecture using an Infrastructure as Code tool.\nWhat is an Application Load Balancer? Elastic Load Balancing automatically distributes your incoming traffic across multiple targets, such as EC2 instances, containers, and IP addresses, in one or more Availability Zones.\nIt monitors the health of its registered targets, and routes traffic only to the healthy targets.\nElastic Load Balancing scales your load balancer as your incoming traffic changes over time.\nElastic Load Balancing supports the following load balancers:\nApplication Load Balancers Network Load Balancers Gateway Load Balancers Classic Load Balancers We are going to find out about Application Load Balancer.\nApplication Load Balancer components A load balancer serves as the single point of contact for clients. The load balancer distributes incoming application traffic across multiple targets, such as EC2 instances, in multiple Availability Zones. This increases the availability of your application.\nA listener checks for connection requests from clients, using the protocol and port that you configure.\nEach target group routes requests to one or more registered targets, such as EC2 instances, using the protocol and port number that you specify.\nWhat is an Auto Scaling Group? Amazon EC2 Auto Scaling helps you ensure that you have the correct number of Amazon EC2 instances available to handle the load for your application.\nYou create collections of EC2 instances, called Auto Scaling groups.\nWith Auto Scaling Groups, you can specify the maximum/minumum of instances in each Auto Scaling Groups, and Amazon EC2 Auto Scaling ensures that your group never goes above/below this size.\nAuto Scaling Benefits Adding Amazon EC2 Auto Scaling to your application architecture is one way to maximize the benefits of the AWS Cloud.\nFault tolerance: Amazon EC2 Auto Scaling can detect when an instance is unhealthy, terminate it, and launch an instance to replace it.\nAvailability: Amazon EC2 Auto Scaling helps ensure that your application always has the right amount of capacity to handle the current traffic demand.\nCost management: Amazon EC2 Auto Scaling can dynamically increase and decrease capacity as needed. Because you pay for the EC2 instances you use, you save money by launching instances when they are needed and terminating them when they aren\u0026rsquo;t.\nSo you can see that registering your Auto Scaling group with an Elastic Load Balancing load balancer helps you set up a load-balanced application.\n-\u0026gt; It will help increase the scalability and availability of your application.\nAmazon Simple Notification Service Amazon Simple Notification Service (Amazon SNS) is a managed service that provides message delivery from publishers to subscribers (also known as producers and consumers).\nWith Amazon SNS, you can configure your Auto Scaling Group to notify important events that affect your application.\nFor example, if you configure your Auto Scaling group to use the autoscaling:EC2_INSTANCE_LAUNCH notification type, and your Auto Scaling group launchs an instance, it sends an email notification.\nSNS Notifications Amazon EC2 Auto Scaling supports sending Amazon SNS notifications when the following events occur.\nEvents Description autoscaling:EC2_INSTANCE_LAUNCH Successful instance launch autoscaling:EC2_INSTANCE_LAUNCH_ERROR Failed instance launch autoscaling:EC2_INSTANCE_TERMINATE Successful instance termination autoscaling:EC2_INSTANCE_TERMINATE_ERROR Failed instance termination The message includes the following information:\nEvent — The event.\nAccountId — The Amazon Web Services account ID.\nAutoScalingGroupName — The name of the Auto Scaling group.\nAutoScalingGroupARN — The ARN of the Auto Scaling group.\nEC2InstanceId — The ID of the EC2 instance.\nContent Introduction to Terraform Define Architecture Infrastructure as Code Deploy Infrastructure and configure SNS Conclusion Clean up Resources "
},
{
	"uri": "/2-defineinfrastructure/2.2compute/",
	"title": "Compute",
	"tags": [],
	"description": "",
	"content": "\nOverview We have an Auto Scaling Group which can scale up or down the number of instance in public Subnet.\nThe EC2 instance in the Auto Scaling Group will automatically run a script to install an Apache Web Server.\nWe also create Target Tracking Policy with policy type is Target tracking scaling, Metric type is Average CPU Utilization, and Target value is 50.\n-\u0026gt; The policy is set to target tracking scaling with a target value of 50% CPU utilization.\nIt ensures that the Auto Scaling Group maintains the desired CPU utilization by scaling the number of instances up or down accordingly.\n"
},
{
	"uri": "/3-infrastructureascode/3.2compute/",
	"title": "Compute",
	"tags": [],
	"description": "",
	"content": "Overview About Compute, we have an Auto Scaling Group. Before we can launch an Auto Scaling Group, we need to define our launch template\nSet up Files In the Compute folder, create four files and name them respectively as main.tf, variables.tf, outputs.tf and install_apache_and_stress.sh.\nFirst, define some variable we are going to use in the variables.tf file.\nvariable \u0026#34;instance_type\u0026#34; {\r}\rvariable \u0026#34;image_id\u0026#34; {\r}\rvariable \u0026#34;keypair_name\u0026#34; {\r}\rvariable \u0026#34;web_server_sg_id\u0026#34; {\r}\rvariable \u0026#34;public_subnet_1_id\u0026#34; {\r}\rvariable \u0026#34;public_subnet_2_id\u0026#34; {\r}\rvariable \u0026#34;alb_tg_arn\u0026#34; {\r} Launch Template The launch template also runs a script to automatically install an Apache Web Server and stress. We will install the commands to install Apache Web Server and stress in the file install_apache_and_stress.sh\nstress is a simple powerful tool designed to impose a configurable amount of CPU, memory, I/O, or disk stress on a Linux system. This tool is valuable for identifying potential weaknesses and ensuring that the system can handle demanding tasks without compromising performance.\n#!/bin/bash\rsudo yum update -y\rsudo yum install -y httpd.x86_64\rsudo systemctl start httpd.service\rsudo systemctl enable httpd.service\recho \u0026#34;Hello First Cloud Journey Program from $(hostname -f)\u0026#34; \u0026gt; /var/www/html/index.html\rsudo amazon-linux-extras install epel -y\rsudo yum install stress -y In the main.tf file, use resources aws_launch_template to create a launch template for Auto Scaling Group.\nresource \u0026#34;aws_launch_template\u0026#34; \u0026#34;one_tier_web_server\u0026#34; {\rname = \u0026#34;Launch-Template-Web-Server\u0026#34;\rinstance_type = var.instance_type\rimage_id = var.image_id\rvpc_security_group_ids = [ var.web_server_sg_id ]\rkey_name = var.keypair_name\ruser_data = filebase64(\u0026#34;${path.module}/install_apache_and_stress.sh\u0026#34;)\rtags = {\r\u0026#34;Name\u0026#34; = \u0026#34;Web Server Launch Template\u0026#34;\r}\r} Auto Scaling Group We can create our Auto Scaling Group after we define our launch template.\nIn the main.tf file, use resources aws_autoscaling_group to create an Auto Scaling Group.\nHere, we define the minimum size of the Auto Scaling Group as 2 and the maximum size as 4, which represents the number of EC2 instances in our Auto Scaling Group.\nWe launch our Auto Scaling Group on 2 public subnets so that we use vpc_zone_identifier to define the subnet IDs to launch resource in.\nresource \u0026#34;aws_autoscaling_group\u0026#34; \u0026#34;one_tier_web_server\u0026#34; {\rname = \u0026#34;ASG-Web-Server\u0026#34;\rmin_size = 2\rmax_size = 4\rdesired_capacity = 2 vpc_zone_identifier = [ var.public_subnet_1_id, var.public_subnet_2_id ]\rtarget_group_arns = [ var.alb_tg_arn ]\rhealth_check_grace_period = 150\rhealth_check_type = \u0026#34;ELB\u0026#34;\rlifecycle {\rcreate_before_destroy = true\r}\rlaunch_template {\rid = aws_launch_template.one_tier_web_server.id\rversion = \u0026#34;$Latest\u0026#34;\r}\r} Target Tracking Policy Plus, we also need to create Target Tracking Policy to check if the CPU Utilization is above 50 then Auto Scaling Group will automatically scale out our EC2 instance. We can use resources aws_autoscaling_policy to perform this action.\nresource \u0026#34;aws_autoscaling_policy\u0026#34; \u0026#34;average_cpu_policy_greater\u0026#34; {\rname = \u0026#34;CPUAveragePolicyGreater\u0026#34;\rpolicy_type = \u0026#34;TargetTrackingScaling\u0026#34;\rautoscaling_group_name = aws_autoscaling_group.one_tier_web_server.name\r# If the CPU Utilization is above 50\rtarget_tracking_configuration {\rpredefined_metric_specification {\rpredefined_metric_type = \u0026#34;ASGAverageCPUUtilization\u0026#34;\r}\rtarget_value = 50.0\r}\r} Output We only need to output the name of the Auto Scaling Group in the outputs.tf file for further purposes.\noutput \u0026#34;asg_name\u0026#34; {\rvalue = aws_autoscaling_group.one_tier_web_server.name\r} Next, we will continue with LoadBalancing module.\n"
},
{
	"uri": "/4.deployinfraandconfiguresns/4.2computeresources/",
	"title": "Compute Resources",
	"tags": [],
	"description": "",
	"content": "Overview Here, we are just reviewing some resources such as our launch template, Auto Scaling Group, and the number of instances that are running. Please access the EC2 interface.\nEC2 instances Two EC2 instances are running at the same time because we have defined the desired capacity as 2 in the Auto Scaling Group, ensuring that there are always two EC2 instances running simultaneously.\nLaunch Template Auto Scaling Group Dynamic Scaling Policies Policy type: Target tracking scaling Metric type: Average CPU Utilization Target value: 50 Finally, we will review the Load Balancing resources and test our web server.\n"
},
{
	"uri": "/2-defineinfrastructure/",
	"title": "Define Architecture",
	"tags": [],
	"description": "",
	"content": "Overview We will analyze our architecture into three components:\nNetworking Load Balancing Compute. By dividing it into such components, building Infrastructure as Code becomes easier to define when we know which component needs to be created first, making program construction more straightforward.\nContent Networking Compute LoadBalancing "
},
{
	"uri": "/1-introductiontoterraform/1.2-terraformcli/",
	"title": "Terraform CLI",
	"tags": [],
	"description": "",
	"content": "Introduction Terraform provides a command line interface (CLI) that can be called with the terraform command once you\u0026rsquo;ve installed Terraform onto your system.\nTo view a list of the commands available in your current Terraform version, run terraform with no additional arguments:\nUsage: terraform [global options] \u0026lt;subcommand\u0026gt; [args]\rThe available commands for execution are listed below.\rThe primary workflow commands are given first, followed by\rless common or more advanced commands.\rMain commands:\rinit Prepare your working directory for other commands\rvalidate Check whether the configuration is valid\rplan Show changes required by the current configuration\rapply Create or update infrastructure\rdestroy Destroy previously-created infrastructure\rAll other commands:\rconsole Try Terraform expressions at an interactive command prompt\rfmt Reformat your configuration in the standard style\rforce-unlock Release a stuck lock on the current workspace\rget Install or upgrade remote Terraform modules\rgraph Generate a Graphviz graph of the steps in an operation\rimport Associate existing infrastructure with a Terraform resource\rlogin Obtain and save credentials for a remote host\rlogout Remove locally-stored credentials for a remote host\rmetadata Metadata related commands\routput Show output values from your root module\rproviders Show the providers required for this configuration\rrefresh Update the state to match remote systems\rshow Show the current state or a saved plan\rstate Advanced state management\rtaint Mark a resource instance as not fully functional\runtaint Remove the 'tainted' state from a resource instance\rversion Show the current Terraform version\rworkspace Workspace management\rGlobal options (use these before the subcommand, if any):\r-chdir=DIR Switch to a different working directory before executing the\rgiven subcommand.\r-help Show this help output, or the help for a specified subcommand.\r-version An alias for the \u0026quot;version\u0026quot; subcommand.\rMain Commands for Terrafrom CLI are:\nSubcommand Description init Initialize your Terraform working directory validate Checks if your configuration is valid plan Show changes that will be made to your current environment apply Create or update your environment destroy Delete the environment that was previously created Terraform init The terraform init command initializes your Terraform working directory.\nTerraform validate The terraform validate command runs checks to verify that the Terraform configuration in the working directory is syntactically valid, but does not validate remote services like remote state and provider APIs.\nIt is commonly used to validate reusable modules and ensure that the attribute names and value types are generally correct.\nTerraform plan The terraform plan command creates and execution plan that provides you a preview of the changes that will be made to your infrastructure (ie. which resources will be created, which will be deleted, and which ones will be modified).\nTerraform apply The terraform apply command executes the actions that are proposed from the Terraform plan. Terraform destroy The terraform destroy command deletes all remote resources that are managed by the current working directory\u0026rsquo;s Terraform configuration.\nNote that if the resource was created outside of the particular Terraform configuration, it will not be destroyed.\n"
},
{
	"uri": "/3-infrastructureascode/",
	"title": "Infrastructure as Code",
	"tags": [],
	"description": "",
	"content": "\nAfter understanding about the three components in the architecture, we can easily structure our source code to build infrastructure.\nIn this step, we will use Terraform to sequentially build modules such as Networking, Compute, and Load Balancing.\nFirst, let\u0026rsquo;s create a folder and name it whatever you want. Open the terminal and type cd to navigate to where you want to create a folder. Using the mkdir command to create a folder. You can see that I create a folder and named it Deploy-Infrastructure. You can create a folder anywhere on your computer and name whatever you want. Then, you can type the following command to open the folder you just created without opening Visual Studio Code. code \u0026lt;yourfolder\u0026gt; In my case, it would be like below. After you run the command, a Visual Studio Code tab will suddenly appear on the computer. Let begin structure our working directory. Create two folders and name them respectively as modules and terraform. You can do this using either the terminal in Visual Studio Code or choosing New Folder on Visual Studio Code. Right now, our working directory looks like this.\nDEPLOY-INFRASTRUCTURE\r├── modules\r├── terraform\rIn the modules folder, create three folders and name them respectively as Networking, Compute, and Load Balancing. We have successfully structured our working directory. Let\u0026rsquo;s go on each modules and build source code to provision infrastructure. Right now, our working directory looks like this.\nDEPLOY-INFRASTRUCTURE\r├── modules\r| |── Compute\r| |── LoadBalancing\r| |── Networking\r├── terraform\rNow, let\u0026rsquo;s move on each modules to build our infrastructure.\nContent Networking Compute Load Balancing Terraform "
},
{
	"uri": "/4.deployinfraandconfiguresns/4.3loadbalancingresources/",
	"title": "Load Balacing Resources",
	"tags": [],
	"description": "",
	"content": "Overview Here, we are reviewing some resources such as the Target Group, Load Balancer, and our web server using a web browser.\nTarget Group You can see that our target group also checks the health of the two EC2 instances.\nLoad Balancers Test Web Server Using Web browser You can test the web server by using the DNS of the ALB. You can copy the value in the terminal or load balancers.\nOpen the web browser, enter the DNS name. You will see like below.\nYou notice that the IP address appears on the screen is 10.10.2.114. Now, let press F5 to refresh the web browser.\nAfter refresing the web browser, the IP address changes to 10.10.1.181. You can notice that these IP addresses are the IP addresses of the two EC2 instances that are running.\nNow, let\u0026rsquo;s configure our Auto Scaling Group with Amazon SNS so that we can get notifications when an instance launches or terminates.\n"
},
{
	"uri": "/2-defineinfrastructure/2.3loadbalancing/",
	"title": "Load Balancing",
	"tags": [],
	"description": "",
	"content": "\nOverview The purpose of the Application Load Balancer here is to route network traffic to a group of stable EC2 instances.\nBefore we can launch the Application Load Balancer, we need to define our target group. In this scenario, Application Load Balancer will route trafic to EC2 instance in Public Subnet, so we can understand that our EC2 instances are the target group.\nPlus, we also need to configure our listener, which is a process that checks for connection requests, using the protocol and port that you configure. You must have at least one listener.\nHere, we will configure our target group to be the Auto Scaling Group and set up the Listener to use the HTTP protocol on port 80.\nAfter gathering information about the three components, you are now able to use Terraform to build infrastructure.\n"
},
{
	"uri": "/3-infrastructureascode/3.3loadbalancing/",
	"title": "Load Balancing",
	"tags": [],
	"description": "",
	"content": "Overview About Load Balancing, Application Load Balancer will route traffic to the Auto Scaling Group. We will define our listener and target group.\nSet up files In the LoadBalancing folder, create three files and name them respectively as main.tf, variables.tf, and outputs.tf.\nDefine some variables we are going to use in the variables.tf file.\nvariable \u0026#34;one_tier_vpc_id\u0026#34; {\r}\rvariable \u0026#34;port\u0026#34; {\r}\rvariable \u0026#34;protocol\u0026#34; {\r}\rvariable \u0026#34;alb_security_group_id\u0026#34; {\r}\rvariable \u0026#34;public_subnet_1_id\u0026#34; {\r}\rvariable \u0026#34;public_subnet_2_id\u0026#34; {\r} Target Group Before we can create an Application Load Balancer, we need to define the Target Group. Here, we use resources aws_lb_target_group to create a Target Group in main.tf file.\nresource \u0026#34;aws_lb_target_group\u0026#34; \u0026#34;instance_tg\u0026#34; {\rname = \u0026#34;ASG-Web-Server-Target-Group\u0026#34;\rport = var.port\rprotocol = var.protocol\rvpc_id = var.one_tier_vpc_id\r} Application Load Balancer Next, we will create an Application Load Balancer using resources aws_lb and aws_lb_listener\nWe define our load balancer type is Application Load Balancer. Attach the public subnet 1 and public subnet 2 to the ALB\nresource \u0026#34;aws_lb\u0026#34; \u0026#34;application_load_balancer\u0026#34; {\rname = \u0026#34;ALB-Web-Server\u0026#34;\rinternal = false\rload_balancer_type = \u0026#34;application\u0026#34;\rsecurity_groups = [ var.alb_security_group_id ]\rsubnets = [ var.public_subnet_1_id, var.public_subnet_2_id ]\r} Listener We use resource aws_lb_listener to confgure listener and routing.\nresource \u0026#34;aws_lb_listener\u0026#34; \u0026#34;application_load_balancer_listener\u0026#34; {\rload_balancer_arn = aws_lb.application_load_balancer.arn\rport = var.port\rprotocol = var.protocol\rdefault_action {\rtype = \u0026#34;forward\u0026#34;\rtarget_group_arn = aws_lb.aws_lb_target_group.instance_tg.arn\r}\r} Output We just output a value like alb_dns to get the DNS in the output.tf file for testing the Auto Scaling Group.\noutput \u0026#34;alb_dns\u0026#34; {\rvalue = aws_lb.application_load_balancer.dns_name\r}\routput \u0026#34;alb_endpoint\u0026#34; {\rvalue = aws_lb.application_load_balancer.dns_name\r}\routput \u0026#34;alb_tg_name\u0026#34; {\rvalue = aws_lb_target_group.instance_tg.name\r}\routput \u0026#34;alb_tg_arn\u0026#34; {\rvalue = aws_lb_target_group.instance_tg.arn\r} Finally, we have completely done buidling the three components of our infrastructure including Networking, Compute and Load Balancing. Next, we will configure our terraform folder so that we can start deploying Infrastructure.\n"
},
{
	"uri": "/1-introductiontoterraform/1.3-setup/",
	"title": "Set Up",
	"tags": [],
	"description": "",
	"content": "Requirments To do this lab, you will need to install Visual Studio Code, AWS CLI and Terraform on your local machine.\nAWS Account You should have an AWS account, which has an IAM user with Administrative permission.\nSet up Visual Studio Code After installing Visual Studio Code successfully, you can download an extension for Terraform called HashiCorp Terraform.\nSet up Terraform You can check if the Terraform is installed on your local machine by opening terminal and typing terraform version\nSet up AWS CLI version 2 You can check if the AWS CLI is installed on your local machine by opening terminal and typing aws --version.\nNext, You will need to create an Access keys. Following these step below to create an Access keys.\nClick on your AWS account and it will appears a tab. Choose Security credentials. Scroll down, you will see an Access keys interface. Click on Create access key. In the Create access key interface, choose Third party service. Then, check the square box. Choose Next. Click on Create access key Click on Download .csv file and Done. Open the .csv file. You will see it has an access key and a secret key.\nOpen the terminal and type aws configure. You will see some things appear in the terminal.\nConfigure like below: AWS Access Key ID: Assign your access key AWS Secret Access Key : Assign your secret access key Default region name: Enter ap-southeast-1 Default output format: Enter json "
},
{
	"uri": "/4.deployinfraandconfiguresns/4.4configuresnsandasg/",
	"title": "Confiugre SNS and Auto Scaling Group",
	"tags": [],
	"description": "",
	"content": "Overview In this part, we will configure an Amazon SNS notification to notify you whenever your Auto Scaling group launches or terminates instances. Following these steps.\nAccess the EC2 interface: Choose Auto Scaling Groups Choose ASG Web Server Click on Activity tab Click on Create notification In the Create notification interface: Send a notification to: Enter AutoScaling-SNS With these recipients: type youremail Click on Create Access SNS interface: Click on Topcis and chosse your Topic (AutoScaling-SNS). Scroll down and click on Create subscription In the Create subscription interface: Protocol: Choose Email Endpoint: Enter your email (This is the email that you want SNS to send notifications to) Scroll down, choose Create subscription You will receive an email from AWS in your mail box. Click on the email, then choose Confirm subscription. You will see a screen that says Subscription confirmed. Now, you have successfully confirmed your Amazozn SNS subscription. You can check the status of the subscriptions. Now, let\u0026rsquo;s SSH into one of the two EC2 instances. SSH successfully. Run the command sudo su to run with the root permission. Type stress to see if the stress is installed. Now, type stress -c 8. The command stress -c 8 is used to generate load on the system by running subprocesses. In this case, -c 8 means it creates 8 worker subprocesses, each of which generates load on the CPU. This helps to test the performance and stability of the system under high CPU load. We need to wait for 5 - 10 minutes for the Auto Scaling Group to collect Metrics. When CPU exceeds the 50% threshold, additional EC2 will be launched according to the scaling policy. Access the EC2 interface, Chọn Auto Scaling groups. Nhấn vào our Auto Scaling Groups (ASG Web Server). You will see that the Auto Scaling Group is preparing to launch a new instance. The Auto Scaling Group launch a new instance. Access Gmail and you will see an email sent from AWS. The notifications contain some following information: Service: AWS Auto Scaling EC2InstanceId: i-04ed494c64679845c Description: Launching a new EC2 instance: i-04ed494c64679845c Event: autoscaling:EC2_INSTANCE_LAUNCH Now, wait for 5 - 10 minutes. The Auto Scaling Group will launch a new instance. Finally, you have learned how to configure Amazon SNS with Auto Scaling Group to notify you of important events that affect your application.\n"
},
{
	"uri": "/4.deployinfraandconfiguresns/",
	"title": "Deploy Infrastructure and Configure SNS",
	"tags": [],
	"description": "",
	"content": "Overview In this part, we will learn how we can use Terraform to provision infrastructure using Terraform CLI.\nNow, open the folder that contains the Terraform source code using Visual Studio Code. You need to open the terminal in Visual Studio Code. Click on View and choose Terminal. After opening the terminal, you will notice that we are in the Deploy-Infrastructure folder. Let\u0026rsquo;s navigate to the terraform folder by typing the following command in the terminal. After you run the command, you are in the terraform folder right now. cd .\\terraform\\ Let\u0026rsquo;s begin by initializing your Terraform workspace. Running the following command in the terminal. terraform init If you successfully run the command, you will see some output in the terminal as shown below. Addtionally, some folders and files will appear in the terraform folder. Terraform also creates a lock file named .terraform.lock.hcl which specifies the exact provider versions used, so that you can control when you want to update the providers used for your project. Initializing the backend...\rInitializing modules...\r- Compute in ..\\modules\\Compute\r- LoadBalancing in ..\\modules\\LoadBalancing\r- Networking in ..\\modules\\Networking\rInitializing provider plugins...\r- Finding hashicorp/aws versions matching \u0026#34;5.43.0\u0026#34;...\r- Finding latest version of hashicorp/http...\r- Installing hashicorp/aws v5.43.0...\r- Installed hashicorp/aws v5.43.0 (signed by HashiCorp)\r- Installing hashicorp/http v3.4.2...\r- Installed hashicorp/http v3.4.2 (signed by HashiCorp)\rTerraform has created a lock file .terraform.lock.hcl to record the provider\rselections it made above. Include this file in your version control repository\rso that Terraform can guarantee to make the same selections by default when\ryou run \u0026#34;terraform init\u0026#34; in the future.\rTerraform has been successfully initialized!\rYou may now begin working with Terraform. Try running \u0026#34;terraform plan\u0026#34; to see\rany changes that are required for your infrastructure. All Terraform commands\rshould now work.\rIf you ever set or change modules or backend configuration for Terraform,\rrerun this command to reinitialize your working directory. If you forget, other\rcommands will detect it and remind you to do so if necessary. Now, we need to validate our configuration. Use the following command in the terminal to do so. terraform validate You will see the output like Success! The configuration is valid. in the terminal. Apply the configuration now with the terraform apply command. Terraform will print output similar to what is shown below. After you run the command, you will see the output in the terminal like this. In the end, you will see a question like \u0026ldquo;Enter a Value\u0026rdquo;. Enter yes so terraform can provision infrastructure. You will see a line Apply complete! Resources: 16 added, 0 changed, 0 destroyed. Remember to copy the value of alb_dns in the terminal. Let’s go to view each resource that Terraform has created. Content Networking resources Compute resources Load Balancing resources Configure SNS and Auto Scaling Group "
},
{
	"uri": "/3-infrastructureascode/3.4terraform/",
	"title": "Terraform",
	"tags": [],
	"description": "",
	"content": "\nOverview With the terraform folder, we can call to some modules such as Networking, Compute and LoadBalancing. We don\u0026rsquo;t need to navigate to each folder and run terraform plan, terraform apply to create each resource.\nSet up files In the terraform folder, create three files and name it respectively as main.tf, outputs.tf and provider.tf.\nSet up Provider In Terraform, a provider is a plugin that acts as an interface between Terraform and an external service or platform. Providers allow Terraform to manage resources, interact with APIs, and perform operations on various cloud platforms, infrastructure services, and third-party systems.\nSome popular Terraform providers:\nazurerm: Azure aws: Amazon Web Services google: Google Cloud Platform Here, we deploy on AWS so we need to configure in the provider.tf file. We will create resource in region Singapore.\nterraform {\rrequired_providers {\raws = {\rsource = \u0026#34;hashicorp/aws\u0026#34;\rversion = \u0026#34;5.43.0\u0026#34;\r} }\r}\rprovider \u0026#34;aws\u0026#34; {\rregion = \u0026#34;ap-southeast-1\u0026#34;\r} Set up Modules Like I said before, you don\u0026rsquo;t need to go to each module and run terraform plan, terraform apply to create each resource. You can define modules in the main.tf file.\n# Define our modules\rmodule \u0026#34;Networking\u0026#34; {\rsource = \u0026#34;../modules/Networking\u0026#34;\rcidr_block = \u0026#34;10.10.0.0/16\u0026#34;\r}\rmodule \u0026#34;Compute\u0026#34; {\rsource = \u0026#34;../modules/Compute\u0026#34;\rinstance_type = \u0026#34;t2.micro\u0026#34;\rimage_id = \u0026#34;ami-04f73ca9a4310089f\u0026#34;\rkeypair_name = \u0026#34;workshop-keypair-2\u0026#34;\rweb_server_sg_id = module.Networking.public_sg_id\rpublic_subnet_1_id = module.Networking.public_subnet_1_id\rpublic_subnet_2_id = module.Networking.public_subnet_2_id\ralb_tg_arn = module.LoadBalancing.alb_tg_arn\r}\rmodule \u0026#34;LoadBalancing\u0026#34; {\rsource = \u0026#34;../modules/LoadBalancing\u0026#34;\rone_tier_vpc_id = module.Networking.vpc_id\rpublic_subnet_1_id = module.Networking.public_subnet_1_id\rpublic_subnet_2_id = module.Networking.public_subnet_2_id\rport = 80\rprotocol = \u0026#34;HTTP\u0026#34;\ralb_security_group_id = module.Networking.alb_sg_id\r} Module Networking In the Networking module, we just need to input the CIDR of the VPC, which is 10.10.0.0/16.\nModule Compute Here, we use the image ID of Amazon Linux 2 AMI and the instance type is t2.micro. You can get these information from AMI.\nAbout keypair_name, access AWS Management Console and search for EC2 (Remember change your region to Singapore) then click on Key Pairs.\nClick on Create key pair Configure like below.\nAfter creating key pair successfully, you will see a notification.\nAbout web_server_sg_id, public_subnet_1_id, public_subnet_2_id and lb_target_group_name, we will take the input from the module Networking.\nModule LoadBalancing We just define protocol HTTTP on port 80. About one_tier_vpc_id, public_subnet_1_id, public_subnet_2_id and alb_security_group_id, we will also take input from the module Networking.\nConclusion By using this advantage, you can automatically create resources using Terraform without manually creating them on the AWS Management Console.\nTerraform will determine the order in which resources need to be created. Initially, the resources within the Networking section will be created first, followed by the resources in the Compute section, and finally, the Load Balancing resources will be set up.\nThen, we can test by using the DNS of ALB to check out our web server. We need to output the DNS of ALB in the outputs.tf file.\noutput \u0026#34;alb_dns\u0026#34; {\rvalue = module.LoadBalancing.alb_dns\r} "
},
{
	"uri": "/5.conclusion/",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": "Overview In this lab, you have learned how to use Terraform to provision a highly available infrastructure on AWS and configure SNS to send notifications. You also see that Elastic Load Balancing ensures EC2 instances are not directly exposed to internet because we access the Auto Scaling Group through the DNS of the ALB.\nAdditional Resources For more hands-on experience with Terraform, I want to provide some documentation and repositories that can help you enhance your Infrastructure as Code (IAC) skills. These repositories also have instructions and demos to help you understand the projects.\nhttps://registry.terraform.io/providers/hashicorp/aws/latest/docs\nDeploy web server with Terraform\nProvision infrastructure for workshop AWS FCJ mission 1\nPlus, here is the full source code Terraform of this lab.\n"
},
{
	"uri": "/6.cleanupresources/",
	"title": "Clean Up Resources",
	"tags": [],
	"description": "",
	"content": "Amazon SNS Following these steps.\nAccess the EC2 interface, choose Auto Scaling groups. Choose our Auto Scaling groups. Click on Activity In the Activity notifications interface, check the square. Go on Actions, choose Delete Click on Delete You will see an notification like below. Access the SNS interface. Click on Subscriptions. Choose the subscription and choose Delete. Choose Delete Now, let\u0026rsquo;s delete our Topics. Choose Topics. Click on the circle. Choose Delete Type delete me and choose Delete Delete Resources using Terraform Following these steps.\nFirst, open the terminal in Visual Studio Code. Type the following command. terraform destroy Optional: You can type terraform destroy -auto-approve to enforce terraform destroy. It means that you don\u0026rsquo;t need to enter yes. After you run the command, you will see the output like this. Enter yes to agree to destroy the resources. The terraform destroy command is a convenient way to destroy all remote objects managed by a particular Terraform configuration. You can see that Terraform will delete the resources for us. We don’t need to go on the AWS Management Console and delete each resource.\nWith Terraform, you can clearly see several benefits, including:\nAutomation: Terraform automates the process of provisioning and managing infrastructure, reducing the risk of human error and increasing efficiency.\nEfficiency: Terraform reduces the time and effort required to manage infrastructure, allowing you to focus on higher-level tasks and increasing overall efficiency.\nCost-Effective: Terraform helps reduce costs by allowing you to manage infrastructure resources more efficiently, reducing waste, and optimizing resource utilization.\nYou can view some resources Terraform has destroyed by using CloudTrail.\nAccess the CloudTrail interface.\nClick on Event history. Here, you can see in the Event history interface. Optional: You can delete the access key and key pair used in this lab. "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]